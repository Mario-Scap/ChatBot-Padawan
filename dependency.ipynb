{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from padawian_list.ipynb\n",
      "importing Jupyter notebook from padawian.ipynb\n"
     ]
    }
   ],
   "source": [
    "import spacy \n",
    "import import_ipynb\n",
    "import padawian_list\n",
    "from padawian_list import feature_list\n",
    "from spacy import displacy\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have force and want to learn to use the lightsaber\n",
      "\n",
      "\n",
      "I, ('nsubj', 'PRON', 'have', Case=Nom|Number=Sing|Person=1|PronType=Prs)\n",
      "have, ('ROOT', 'VERB', 'have', Mood=Ind|Tense=Pres|VerbForm=Fin)\n",
      "force, ('dobj', 'NOUN', 'have', Number=Sing)\n",
      "and, ('cc', 'CCONJ', 'have', ConjType=Cmp)\n",
      "want, ('conj', 'VERB', 'have', Tense=Pres|VerbForm=Fin)\n",
      "to, ('aux', 'PART', 'use', )\n",
      "learn, ('xcomp', 'VERB', 'want', VerbForm=Inf)\n",
      "use, ('xcomp', 'VERB', 'learn', VerbForm=Inf)\n",
      "the, ('det', 'DET', 'lightsaber', Definite=Def|PronType=Art)\n",
      "lightsaber, ('dobj', 'NOUN', 'use', Number=Sing)\n",
      "\n",
      "\n",
      "Parole chiave: ['force', 'lightsaber']\n",
      "\n",
      "\n",
      "Numero Parole Chiave: 2\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "#devo trovare tutte le dipendenze per una certa caratteristica dei padawain\n",
    "class Dependency: \n",
    "    def __init__(self, text):\n",
    "        self.text = text\n",
    "        self.nlp = spacy.load(\"en_core_web_sm\")\n",
    "        self.doc = self.nlp(self.text)\n",
    "\n",
    "    #cerca le dipendenze di tutte le parole (pos tagging)\n",
    "    def find_dependency(self):\n",
    "        dict_of_dependency = {}\n",
    "        for token in self.doc:\n",
    "            dict_of_dependency[token.text] = token.dep_, token.pos_, token.head.text, token.morph\n",
    "        \n",
    "        return dict_of_dependency\n",
    "\n",
    "    #visualizza le dipendenze\n",
    "    def visualize_dependency(self):\n",
    "        displacy.render(self.doc, style=\"dep\")\n",
    "        return self.doc\n",
    "\n",
    "\n",
    "    #vado a controllare le dependency per le features dei padawain\n",
    "    def check_dependency_padawian(self):\n",
    "        check_list = [feature.split() for feature in feature_list] #non più feature list ma è la lista delle feature della specifica categoria\n",
    "        correct = []\n",
    "\n",
    "        for token in self.doc: #vado nel testo\n",
    "            for f in check_list: #vado nella lista delle features\n",
    "                if token.text == f[0]: #se la feature è uguale al token    \n",
    "                    if len(f) == 1:\n",
    "                        correct.append(token.text)\n",
    "                    \n",
    "                    #se e' una parola composta allora non va bene\n",
    "                    elif token.i == len(self.doc) - 1 and len(f) > 1 :\n",
    "                        correct.append(None)\n",
    "                    \n",
    "                    else:\n",
    "                        for i in range(1, len(f)):\n",
    "                            if token.nbor(i).text != f[i]:\n",
    "                                correct.append(None)\n",
    "                            \n",
    "                            if token.i == len(self.doc) - 1 and len(f) > 1 :\n",
    "                                correct.append(None)\n",
    "                        \n",
    "                        return \"\".join(f)\n",
    "                            \n",
    "        correct = [x for x in correct if x is not None]\n",
    "        return correct\n",
    "    \n",
    "     #fare funzione che prende la risposta che ci si aspetta e la confronta con la risposta data dall'utente\n",
    "    def check_response(self, response):\n",
    "        return True\n",
    "    \n",
    "    def features_in_text(self):\n",
    "        return len(self.check_dependency_padawian())\n",
    "\n",
    "#Praticamente cerco di capire se la frase che e' stata detta e' positiva o negativa. In questo modo nel dialog system gestisco la tipologia di risposta\n",
    " \"\"\"\n",
    "    def check_response_type(self):\n",
    "        self.pos = True\n",
    "        for token in self.doc:\n",
    "            if token.text == 'no' or token.text == 'not' or \"Neg\" in token.morph.get(\"Polarity\"):\n",
    "                self.pos = False\n",
    "            \n",
    "        return self.pos\n",
    " \"\"\"       \n",
    "if __name__ == \"__main__\":\n",
    "    sent = Dependency(\"I have force and want to learn to use the lightsaber\") #Piccola frase di esempio. In questo caso va a pescare dalla losta force e lightsaber\n",
    "    print(sent.text)\n",
    "    print(\"\\n\")\n",
    "    #print(\"Visualize dependency: \", sent.visualize_dependency())\n",
    "    dependencies = sent.find_dependency()\n",
    "\n",
    "    for key, value in dependencies.items():\n",
    "        print(f\"{key}, {value}\")\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    print(f\"Parole chiave: {sent.check_dependency_padawian()}\")\n",
    "    print(\"\\n\")\n",
    "    print(f\"Numero Parole Chiave: {sent.features_in_text()}\")\n",
    "    print(f\"{sent.check_response_type()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
